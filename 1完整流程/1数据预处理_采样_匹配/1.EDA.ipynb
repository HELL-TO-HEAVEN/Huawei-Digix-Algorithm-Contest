{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'data/train_20190518.csv',header=None, names = ['label', 'uId', 'adId', 'operTime', 'siteId', 'slotId', 'contentId', 'netType'])\n",
    "test = pd.read_csv(r'data/test_20190518.csv',header=None, names = ['label', 'uId', 'adId', 'operTime', 'siteId', 'slotId', 'contentId', 'netType'] )\n",
    "user_info = pd.read_csv(r'data/clean_user_info.csv',header=None, names =['uId', 'age', 'gender', 'city', 'province', 'phoneType', 'carrier'])\n",
    "ad_info = pd.read_csv(r'data/clean_ad_info.csv',header=None, names =['adId', 'billId', 'primId','creativeType', 'intertype', 'spreadAppId'])\n",
    "content_info = pd.read_csv(r'data/clean_content_info.csv',header=None, names =['contentId', 'firstClass', 'secondClass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train size:',train.shape)\n",
    "print('test size:',test.shape)\n",
    "print('user_info size:',user_info.shape)\n",
    "print('ad_info size:',ad_info.shape)\n",
    "print('content_info size:',content_info.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理user_info数据\n",
    "\n",
    "user_info包含很多缺失值，经过观察，只有phoneType这个特征，只有5个缺失值，并且其总共有512个种类，根据常识，使用同种手机的人群特征也是比较类似的，所以根据每一类手机将用户分类，用此类手机中其他特征的众数，来填充此类用户中的缺失值，填充的原则就是取出现次数最多的元素进行填充\n",
    "\n",
    "如果某一类手机的某个特征中，全部都是缺失值，则使用所有数据中出现次数最多的元素进行填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_type = user_info['phoneType'].unique().tolist()\n",
    "\n",
    "# 计算每个特征中，出现次数最多的那个元素\n",
    "max_total_age = pd.value_counts(user_info['age'])\n",
    "max_total_age = max_total_age.index[0]\n",
    "\n",
    "max_total_gender = pd.value_counts(user_info['gender'])\n",
    "max_total_gender = max_total_gender.index[0]\n",
    "\n",
    "max_total_city = pd.value_counts(user_info['city'])\n",
    "max_total_city = max_total_city.index[0]\n",
    "\n",
    "max_total_province = pd.value_counts(user_info['province'])\n",
    "max_total_province = max_total_province.index[0]\n",
    "\n",
    "max_total_phoneType = pd.value_counts(user_info['phoneType'])\n",
    "max_total_phoneType = max_total_phoneType.index[0]\n",
    "\n",
    "max_total_carrier = pd.value_counts(user_info['carrier'])\n",
    "max_total_carrier = max_total_carrier.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of 1\n",
      "number of 2\n",
      "number of 3\n",
      "number of 4\n",
      "number of 5\n",
      "number of 6\n",
      "number of 7\n",
      "number of 8\n",
      "number of 9\n",
      "number of 10\n",
      "number of 11\n",
      "number of 12\n",
      "number of 13\n",
      "number of 14\n",
      "number of 15\n",
      "number of 16\n",
      "number of 17\n",
      "number of 18\n",
      "number of 19\n",
      "number of 20\n",
      "number of 21\n",
      "number of 22\n",
      "number of 23\n",
      "number of 24\n",
      "number of 25\n",
      "number of 26\n",
      "number of 27\n",
      "number of 28\n",
      "number of 29\n",
      "number of 30\n",
      "number of 31\n",
      "number of 32\n",
      "number of 33\n",
      "number of 34\n",
      "number of 35\n",
      "number of 36\n",
      "number of 37\n",
      "number of 38\n",
      "number of 39\n",
      "number of 40\n",
      "number of 41\n",
      "number of 42\n",
      "number of 43\n",
      "number of 44\n",
      "number of 45\n",
      "number of 46\n",
      "number of 47\n",
      "number of 48\n",
      "number of 49\n",
      "number of 50\n",
      "number of 51\n",
      "number of 52\n",
      "number of 53\n",
      "number of 54\n",
      "number of 55\n",
      "number of 56\n",
      "number of 57\n",
      "number of 58\n",
      "number of 59\n",
      "number of 60\n",
      "number of 61\n",
      "number of 62\n",
      "number of 63\n",
      "number of 64\n",
      "number of 65\n",
      "number of 66\n",
      "number of 67\n",
      "number of 68\n",
      "number of 69\n",
      "number of 70\n",
      "number of 71\n",
      "number of 72\n",
      "number of 73\n",
      "number of 74\n",
      "number of 75\n",
      "number of 76\n",
      "number of 77\n",
      "number of 78\n",
      "number of 79\n",
      "number of 80\n",
      "number of 81\n",
      "number of 82\n",
      "number of 83\n",
      "number of 84\n",
      "number of 85\n",
      "number of 86\n",
      "number of 87\n",
      "number of 88\n",
      "number of 89\n",
      "number of 90\n",
      "number of 91\n",
      "number of 92\n",
      "number of 93\n",
      "number of 94\n",
      "number of 95\n",
      "number of 96\n",
      "number of 97\n",
      "number of 98\n",
      "number of 99\n",
      "number of 100\n",
      "number of 101\n",
      "number of 102\n",
      "number of 103\n",
      "number of 104\n",
      "number of 105\n",
      "number of 106\n",
      "number of 107\n",
      "number of 108\n",
      "number of 109\n",
      "number of 110\n",
      "number of 111\n",
      "number of 112\n",
      "number of 113\n",
      "number of 114\n",
      "number of 115\n",
      "number of 116\n",
      "number of 117\n",
      "number of 118\n",
      "number of 119\n",
      "number of 120\n",
      "number of 121\n",
      "number of 122\n",
      "number of 123\n",
      "number of 124\n",
      "number of 125\n",
      "number of 126\n",
      "number of 127\n",
      "number of 128\n",
      "number of 129\n",
      "number of 130\n",
      "number of 131\n",
      "number of 132\n",
      "number of 133\n",
      "number of 134\n",
      "number of 135\n",
      "number of 136\n",
      "number of 137\n",
      "number of 138\n",
      "number of 139\n",
      "number of 140\n",
      "number of 141\n",
      "number of 142\n",
      "number of 143\n",
      "number of 144\n",
      "number of 145\n",
      "number of 146\n",
      "number of 147\n",
      "number of 148\n",
      "number of 149\n",
      "number of 150\n",
      "number of 151\n",
      "number of 152\n",
      "number of 153\n",
      "number of 154\n",
      "number of 155\n",
      "number of 156\n",
      "number of 157\n",
      "number of 158\n",
      "number of 159\n",
      "number of 160\n",
      "number of 161\n",
      "number of 162\n",
      "number of 163\n",
      "number of 164\n",
      "number of 165\n",
      "number of 166\n",
      "number of 167\n",
      "number of 168\n",
      "number of 169\n",
      "number of 170\n",
      "number of 171\n",
      "number of 172\n",
      "number of 173\n",
      "number of 174\n",
      "number of 175\n",
      "number of 176\n",
      "number of 177\n",
      "number of 178\n",
      "number of 179\n",
      "number of 180\n",
      "number of 181\n",
      "number of 182\n",
      "number of 183\n",
      "number of 184\n",
      "number of 185\n",
      "number of 186\n",
      "number of 187\n",
      "number of 188\n",
      "number of 189\n",
      "number of 190\n",
      "number of 191\n",
      "number of 192\n",
      "number of 193\n",
      "number of 194\n",
      "number of 195\n",
      "number of 196\n",
      "number of 197\n",
      "number of 198\n",
      "number of 199\n",
      "number of 200\n",
      "number of 201\n",
      "number of 202\n",
      "number of 203\n",
      "number of 204\n",
      "number of 205\n",
      "number of 206\n",
      "number of 207\n",
      "number of 208\n",
      "number of 209\n",
      "number of 210\n",
      "number of 211\n",
      "number of 212\n",
      "number of 213\n",
      "number of 214\n",
      "number of 215\n",
      "number of 216\n",
      "number of 217\n",
      "number of 218\n",
      "number of 219\n",
      "number of 220\n",
      "number of 221\n",
      "number of 222\n",
      "number of 223\n",
      "number of 224\n",
      "number of 225\n",
      "number of 226\n",
      "number of 227\n",
      "number of 228\n",
      "number of 229\n",
      "number of 230\n",
      "number of 231\n",
      "number of 232\n",
      "number of 233\n",
      "number of 234\n",
      "number of 235\n",
      "number of 236\n",
      "number of 237\n",
      "number of 238\n",
      "number of 239\n",
      "number of 240\n",
      "number of 241\n",
      "number of 242\n",
      "number of 243\n",
      "number of 244\n",
      "number of 245\n",
      "number of 246\n",
      "number of 247\n",
      "number of 248\n",
      "number of 249\n",
      "number of 250\n",
      "number of 251\n",
      "number of 252\n",
      "number of 253\n",
      "number of 254\n",
      "number of 255\n",
      "number of 256\n",
      "number of 257\n",
      "number of 258\n",
      "number of 259\n",
      "number of 260\n",
      "number of 261\n",
      "number of 262\n",
      "number of 263\n",
      "number of 264\n",
      "number of 265\n",
      "number of 266\n",
      "number of 267\n",
      "number of 268\n",
      "number of 269\n",
      "number of 270\n",
      "number of 271\n",
      "number of 272\n",
      "number of 273\n",
      "number of 274\n",
      "number of 275\n",
      "number of 276\n",
      "number of 277\n",
      "number of 278\n",
      "number of 279\n",
      "number of 280\n",
      "number of 281\n",
      "number of 282\n",
      "number of 283\n",
      "number of 284\n",
      "number of 285\n",
      "number of 286\n",
      "number of 287\n",
      "number of 288\n",
      "number of 289\n",
      "number of 290\n",
      "number of 291\n",
      "number of 292\n",
      "number of 293\n",
      "number of 294\n",
      "number of 295\n",
      "number of 296\n",
      "number of 297\n",
      "number of 298\n",
      "number of 299\n",
      "number of 300\n",
      "number of 301\n",
      "number of 302\n",
      "number of 303\n",
      "number of 304\n",
      "number of 305\n",
      "number of 306\n",
      "number of 307\n",
      "number of 308\n",
      "number of 309\n",
      "number of 310\n"
     ]
    }
   ],
   "source": [
    "# 先将phoneType为缺失值的那5个数据用所有数据出现次数最多的元素继续宁填充\n",
    "tem_int = user_info[user_info['phoneType'].isnull()]['age'].fillna(max_total_age)\n",
    "user_info.loc[user_info['phoneType'].isnull(),'age'] = tem_int\n",
    "\n",
    "tem_int = user_info[user_info['phoneType'].isnull()]['gender'].fillna(max_total_gender)\n",
    "user_info.loc[user_info['phoneType'].isnull(),'gender'] = tem_int\n",
    "\n",
    "tem_int = user_info[user_info['phoneType'].isnull()]['province'].fillna(max_total_province)\n",
    "user_info.loc[user_info['phoneType'].isnull(),'province'] = tem_int\n",
    "\n",
    "tem_int = user_info[user_info['phoneType'].isnull()]['carrier'].fillna(max_total_carrier)\n",
    "user_info.loc[user_info['phoneType'].isnull(),'carrier'] = tem_int\n",
    "\n",
    "tem_int = user_info[user_info['phoneType'].isnull()]['phoneType'].fillna(max_total_phoneType)\n",
    "user_info.loc[user_info['phoneType'].isnull(),'phoneType'] = tem_int\n",
    "\n",
    "# 用手机类型进行分类，分别处理每个批量的数据\n",
    "num = 1\n",
    "for i in phone_type:\n",
    "    data = user_info[user_info['phoneType'] == i]\n",
    "    if (data['age'].isnull().sum() == len(data) or \n",
    "       data['gender'].isnull().sum() == len(data) or\n",
    "       data['city'].isnull().sum() == len(data) or\n",
    "       data['province'].isnull().sum() == len(data) or\n",
    "       data['carrier'].isnull().sum() == len(data)):\n",
    "        \n",
    "        tem_int = user_info[user_info['phoneType'] == i]['age'].fillna(max_total_age)\n",
    "        user_info.loc[user_info['phoneType'] == i,'age'] = tem_int\n",
    "        \n",
    "        tem_int = user_info[user_info['phoneType'] == i]['gender'].fillna(max_total_gender)\n",
    "        user_info.loc[user_info['phoneType'] == i,'gender'] = tem_int\n",
    "        \n",
    "        tem_int = user_info[user_info['phoneType'] == i]['city'].fillna(max_total_city)\n",
    "        user_info.loc[user_info['phoneType'] == i,'city'] = tem_int\n",
    "        \n",
    "        tem_int = user_info[user_info['phoneType'] == i]['province'].fillna(max_total_province)\n",
    "        user_info.loc[user_info['phoneType'] == i,'province'] = tem_int\n",
    "        \n",
    "        tem_int = user_info[user_info['phoneType'] == i]['carrier'].fillna(max_total_carrier)\n",
    "        user_info.loc[user_info['phoneType'] == i,'carrier'] = tem_int\n",
    "        \n",
    "    else:\n",
    "        max_age = pd.value_counts(data['age'])\n",
    "        max_age = max_age.index[0]\n",
    "\n",
    "        max_gender = pd.value_counts(data['gender'])\n",
    "        max_gender = max_gender.index[0]\n",
    "\n",
    "        max_city = pd.value_counts(data['city'])\n",
    "        max_city = max_city.index[0]\n",
    "\n",
    "        max_province = pd.value_counts(data['province'])\n",
    "        max_province = max_province.index[0]\n",
    "\n",
    "        max_carrier = pd.value_counts(data['carrier'])\n",
    "        max_carrier = max_carrier.index[0]\n",
    "        \n",
    "        tem_int = user_info[user_info['phoneType'] == i]['age'].fillna(max_age)\n",
    "        user_info.loc[user_info['phoneType'] == i,'age'] = tem_int\n",
    "\n",
    "        tem_int = user_info[user_info['phoneType'] == i]['gender'].fillna(max_gender)\n",
    "        user_info.loc[user_info['phoneType'] == i,'gender'] = tem_int\n",
    "\n",
    "        tem_int = user_info[user_info['phoneType'] == i]['city'].fillna(max_city)\n",
    "        user_info.loc[user_info['phoneType'] == i,'city'] = tem_int\n",
    "\n",
    "        tem_int = user_info[user_info['phoneType'] == i]['province'].fillna(max_province)\n",
    "        user_info.loc[user_info['phoneType'] == i,'province'] = tem_int\n",
    "\n",
    "        tem_int = user_info[user_info['phoneType'] == i]['carrier'].fillna(max_carrier)\n",
    "        user_info.loc[user_info['phoneType'] == i,'carrier'] = tem_int\n",
    "    \n",
    "#     监控处理过程\n",
    "    print('number of',num)\n",
    "    num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.to_csv('data/clean_user_info.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理ad_info数据\n",
    "\n",
    "１．付费方式＂billId＂需要数值化\n",
    "\n",
    "２．spreadAppId（广告对应的appId）这个特征就有缺失值\n",
    "\n",
    "解决方案：将spreadAppId作为标签，用前五个特征进行训练，使用KNN算法，预测无标签数据的标签，在验证数据集上，得到了79%的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符数据离散化 \n",
    "labels_3 = ad_info['billId'].unique().tolist()\n",
    "q = 1\n",
    "for i in labels_3:\n",
    "    ad_info.loc[ad_info['billId'] ==i,'billId'] = q\n",
    "    q += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_info[ad_info['spreadAppId'].isnull()]['primId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = ad_info[ad_info['spreadAppId'].notnull()]\n",
    "y = X_data['spreadAppId']\n",
    "X =  X_data.drop(['spreadAppId'],axis = 1)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2)\n",
    "knn=KNeighborsClassifier(n_neighbors=2,weights='distance')\n",
    "knn.fit(X_train,Y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('accuracy of KNN',accuracy_score(Y_test, y_pred))\n",
    "\n",
    "null_data = ad_info[ad_info['spreadAppId'].isnull()]\n",
    "null_data = null_data.drop(['spreadAppId'],axis = 1)\n",
    "y_pred_null = knn.predict(null_data)\n",
    "null_data['spreadAppId'] = y_pred_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_info = pd.concat([X_data,null_data])\n",
    "cad_info = clean_ad_info.sort_index()\n",
    "ad_info.to_csv('data/clean_ad_info.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理content_info数据\n",
    "\n",
    "对于content info文件，特征secondClass是对firstClass的一个更详细的分类。对于每一个firstClass，同一个firstClass下对应的secondClass是固定且唯一的。并且文件中只有secondClass存在缺失值，因此先将数据根据firstClass进行分类，再在每一个小类中，用seccondClass出现次数最多的元素填充缺失值\n",
    "\n",
    "再将字符串特征转换成数值特征（从１开始）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class = content_info['firstClass'].unique().tolist()\n",
    "\n",
    "for i in first_class:\n",
    "    data = content_info[content_info['firstClass'] == i]   \n",
    "    \n",
    "    if (data['secondClass'].isnull().sum() == len(data)):   \n",
    "        content_info.loc[content_info['firstClass'] == i,'secondClass'] = i\n",
    "        \n",
    "    else:\n",
    "        max_secondclass = pd.value_counts(data['secondClass'])\n",
    "        max_secondclass = max_secondclass.index[0]\n",
    "\n",
    "        tem_int = content_info[content_info['firstClass'] == i]['secondClass'].fillna(max_secondclass)\n",
    "        content_info.loc[content_info['firstClass'] == i,'secondClass'] = tem_int\n",
    "        \n",
    "        \n",
    "content_info[\"firstClass\"] = pd.factorize(content_info[\"firstClass\"])[0].astype(np.uint64)\n",
    "content_info[\"secondClass\"] = pd.factorize(content_info[\"secondClass\"])[0].astype(np.uint64)\n",
    "\n",
    "content_info.loc[content_info['firstClass'] ==0,'firstClass'] = 23\n",
    "content_info.loc[content_info['secondClass'] ==0,'secondClass'] = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_info.to_csv('clean_contentId_info.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看训练数据与测试数据\n",
    "\n",
    "１．训练数据中无缺失值，无需处理\n",
    "\n",
    "２．测试数据中，＂contentId＂存在缺失值，数目并不多，采用众数填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_contendId = pd.value_counts(test['contentId'])\n",
    "max_contendId = max_contendId.index[0]\n",
    "\n",
    "tem_int = test[test['contentId'].isnull()]['contentId'].fillna(max_contendId)\n",
    "test.loc[test['contentId'].isnull(),'contentId'] = tem_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label        False\n",
       "uId          False\n",
       "adId         False\n",
       "operTime     False\n",
       "siteId       False\n",
       "slotId       False\n",
       "contentId    False\n",
       "netType      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/clean_test.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
